{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parler import Parler\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following requires the user to enter a search term and returns the top 20 hashtags sorted by volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = input('Enter search term: ')\n",
    "\n",
    "dict1 = {}\n",
    "dict1['tag'] = []\n",
    "dict1['totalPosts'] = []\n",
    "\n",
    "print('Collecting hashtags that contain ' + q + '..')\n",
    "\n",
    "fetch = Parler().getHashtags(q)\n",
    "\n",
    "for x in fetch['tags']:\n",
    "    dict1['tag'].append(x['tag'])\n",
    "    dict1['totalPosts'].append(x['totalPosts'])\n",
    "\n",
    "df_tags = pd.DataFrame.from_dict(dict1)\n",
    "\n",
    "print(df_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 affiliate domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following fetches the domains for a specified amount of pages (in this case 5) of affiliate news posts. Just change the \"5\" to a higher number to increase the number of posts you want to collect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "dict1[\"domain\"] = []\n",
    "\n",
    "fetch = Parler().getAffiliateFeed()\n",
    "next_cursor = fetch[\"next\"]\n",
    "\n",
    "# There are a lot of domains named \"feedproxy.google.com\", so I added a few lines to get the site if this is the domain\n",
    "for x in fetch[\"links\"]:\n",
    "    if x[\"domain\"] != \"feedproxy.google.com\":\n",
    "        dict1[\"domain\"].append(x[\"domain\"])\n",
    "    elif x[\"domain\"] == \"feedproxy.google.com\":\n",
    "        dict1[\"domain\"].append(x[\"metadata\"][\"site\"])\n",
    "\n",
    "# Change \"5\" to a higher number to collect more posts\n",
    "for i in tqdm(range(1,5),desc=\"Collecting affiliate data...\"):\n",
    "    fetch = Parler().getAffiliateFeed(cursor=next_cursor)\n",
    "    next_cursor = fetch[\"next\"]\n",
    "    for x in fetch[\"links\"]:\n",
    "        if x[\"domain\"] != \"feedproxy.google.com\":\n",
    "            dict1[\"domain\"].append(x[\"domain\"])\n",
    "        elif x[\"domain\"] == \"feedproxy.google.com\":\n",
    "            dict1[\"domain\"].append(x[\"metadata\"][\"site\"])\n",
    "\n",
    "df_affiliate_data = pd.DataFrame.from_dict(dict1)\n",
    "\n",
    "# Return 10 most frequent domains\n",
    "most_freq = pd.Series(' '.join(df_affiliate_data[\"domain\"]).lower().split()).value_counts()[:10]\n",
    "print(most_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve all posts which contain a specified hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pages through and collects all posts which contain a specified hashtag and puts the id of the post and body of the post into a data frame for manipulation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag = input('Enter hashtag: ')\n",
    "\n",
    "dict1 = {}\n",
    "dict1[\"id\"] = []\n",
    "dict1[\"body\"] = []\n",
    "\n",
    "df_hashtag_data = pd.DataFrame()\n",
    "    \n",
    "print(\"Collecting data for #\" + hashtag + \"...\")\n",
    "    \n",
    "fetch = Parler().getHashtagFeed(hashtag)\n",
    "next_cursor = fetch[\"next\"]\n",
    "    \n",
    "for x in fetch[\"posts\"]:\n",
    "    dict1[\"id\"].append(x[\"id\"])\n",
    "    dict1[\"body\"].append(x[\"body\"])\n",
    "\n",
    "while fetch[\"last\"] == False:\n",
    "    fetch = Parler().getHashtagFeed(hashtag,cursor=next_cursor)\n",
    "    next_cursor = fetch[\"next\"]\n",
    "    for x in fetch[\"posts\"]:\n",
    "        dict1[\"id\"].append(x[\"id\"])\n",
    "        dict1[\"body\"].append(x[\"body\"])\n",
    "    \n",
    "df_hashtag_data = pd.DataFrame.from_dict(dict1)\n",
    "df_hashtag_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
