{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parler.main import Parler\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following requires the user to enter a search term and returns the top 20 hashtags sorted by volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting hashtags that contain wpww..\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    tag totalPosts\n",
       "0  wpww        127"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tag</th>\n      <th>totalPosts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>wpww</td>\n      <td>127</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "q = input('Enter search term: ')\n",
    "\n",
    "dict1 = {}\n",
    "dict1['tag'] = []\n",
    "dict1['totalPosts'] = []\n",
    "\n",
    "print('Collecting hashtags that contain ' + q + '..')\n",
    "\n",
    "fetch_hashtags = Parler().hashtags(q)\n",
    "\n",
    "for x in fetch_hashtags['tags']:\n",
    "    dict1['tag'].append(x['tag'])\n",
    "    dict1['totalPosts'].append(x['totalPosts'])\n",
    "\n",
    "df_tags = pd.DataFrame.from_dict(dict1)\n",
    "\n",
    "df_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 affiliate domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following fetches the domains for a specified amount of pages (in this case 5) of affiliate news posts. Just change the \"5\" to a higher number to increase the number of posts you want to collect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Collecting affiliate data...: 100%|██████████| 9/9 [00:05<00:00,  1.64it/s]justthenews.com          20\n",
      "pagesix.com              20\n",
      "bizpacreview.com         20\n",
      "lacortenews.com          20\n",
      "thepostmillennial.com    20\n",
      "@zerohedge               20\n",
      "bigleaguepolitics.com    10\n",
      "rt.com                   10\n",
      "waynedupree.com          10\n",
      "ammoland.com             10\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict1 = {}\n",
    "dict1[\"domain\"] = []\n",
    "\n",
    "fetch_affiliates = Parler().affiliates()\n",
    "next_cursor = fetch_affiliates[\"next\"]\n",
    "\n",
    "# There are a lot of domains named \"feedproxy.google.com\", so I added a few lines to get the site if this is the domain\n",
    "for x in fetch_affiliates[\"links\"]:\n",
    "    if x[\"domain\"] != \"feedproxy.google.com\":\n",
    "        dict1[\"domain\"].append(x[\"domain\"])\n",
    "    elif x[\"domain\"] == \"feedproxy.google.com\":\n",
    "        dict1[\"domain\"].append(x[\"metadata\"][\"site\"])\n",
    "\n",
    "# Change \"10\" to a higher number to collect more posts\n",
    "for i in tqdm(range(1,10),desc=\"Collecting affiliate data...\"):\n",
    "    fetch_affiliates = Parler().affiliates(cursor=next_cursor)\n",
    "    next_cursor = fetch_affiliates[\"next\"]\n",
    "    for x in fetch_affiliates[\"links\"]:\n",
    "        if x[\"domain\"] != \"feedproxy.google.com\":\n",
    "            dict1[\"domain\"].append(x[\"domain\"])\n",
    "        elif x[\"domain\"] == \"feedproxy.google.com\":\n",
    "            dict1[\"domain\"].append(x[\"metadata\"][\"site\"])\n",
    "\n",
    "df_affiliate_data = pd.DataFrame.from_dict(dict1)\n",
    "\n",
    "# Return 10 most frequent domains\n",
    "most_freq = pd.Series(' '.join(df_affiliate_data[\"domain\"]).lower().split()).value_counts()[:10]\n",
    "print(most_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve all posts which contain a specified hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pages through and collects all posts which contain a specified hashtag and puts the id of the post and body of the post into a data frame for manipulation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting data for #wpww...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   id  \\\n",
       "0    00b157d3554e4b469f5224daa7f9dfda   \n",
       "1    8548fe7ff75249a8a9b517da13a87f49   \n",
       "2    f3263fff0b1d4b08b062f2eefdd23e09   \n",
       "3    c297ac3802b8441bb65d04b564c30eff   \n",
       "4    f3a0d17aa4794653bfb03164399359c0   \n",
       "..                                ...   \n",
       "113  c810ab3811d041aab4b23a94050a2fd7   \n",
       "114  05c80c6dafa54e2caa8a3b4c4376dda3   \n",
       "115  821474da654a451993ccadb5f2210271   \n",
       "116  19aebc19584e4fa5bfb82edb1d10b6ca   \n",
       "117  f188d303d7464c6d840c1a83e810f134   \n",
       "\n",
       "                                                  body  \n",
       "0    It’s amazing to me the parallels in time that ...  \n",
       "1    It’s real. \\n\\n#theeternaljew #itsthejewsdummy...  \n",
       "2    500 followers. 500 seekers of truth. 500 sons ...  \n",
       "3    The hypocrisy...the lies...the double standard...  \n",
       "4    The fact that there is a group of satanic pedo...  \n",
       "..                                                 ...  \n",
       "113  #antifa #notracist #libtards #blacklivesmatter...  \n",
       "114  24 hour ban on yid run Facebook because of my ...  \n",
       "115                                     #wp #wlw #wpww  \n",
       "116  #Voting takes a plan:\\n▫️Will you #vote on #El...  \n",
       "117  #Whites, reject legal notions of “#HateSpeech”...  \n",
       "\n",
       "[118 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00b157d3554e4b469f5224daa7f9dfda</td>\n      <td>It’s amazing to me the parallels in time that ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8548fe7ff75249a8a9b517da13a87f49</td>\n      <td>It’s real. \\n\\n#theeternaljew #itsthejewsdummy...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f3263fff0b1d4b08b062f2eefdd23e09</td>\n      <td>500 followers. 500 seekers of truth. 500 sons ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c297ac3802b8441bb65d04b564c30eff</td>\n      <td>The hypocrisy...the lies...the double standard...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>f3a0d17aa4794653bfb03164399359c0</td>\n      <td>The fact that there is a group of satanic pedo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>c810ab3811d041aab4b23a94050a2fd7</td>\n      <td>#antifa #notracist #libtards #blacklivesmatter...</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>05c80c6dafa54e2caa8a3b4c4376dda3</td>\n      <td>24 hour ban on yid run Facebook because of my ...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>821474da654a451993ccadb5f2210271</td>\n      <td>#wp #wlw #wpww</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>19aebc19584e4fa5bfb82edb1d10b6ca</td>\n      <td>#Voting takes a plan:\\n▫️Will you #vote on #El...</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>f188d303d7464c6d840c1a83e810f134</td>\n      <td>#Whites, reject legal notions of “#HateSpeech”...</td>\n    </tr>\n  </tbody>\n</table>\n<p>118 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "hashtag = input('Enter hashtag: ')\n",
    "\n",
    "dict1 = {}\n",
    "dict1[\"id\"] = []\n",
    "dict1[\"body\"] = []\n",
    "\n",
    "df_hashtag_data = pd.DataFrame()\n",
    "    \n",
    "print(\"Collecting data for #\" + hashtag + \"...\")\n",
    "    \n",
    "fetch = Parler().hashtag_feed(hashtag)\n",
    "next_cursor = fetch[\"next\"]\n",
    "    \n",
    "for x in fetch[\"posts\"]:\n",
    "    dict1[\"id\"].append(x[\"id\"])\n",
    "    dict1[\"body\"].append(x[\"body\"])\n",
    "\n",
    "while fetch[\"last\"] == False:\n",
    "    fetch = Parler().hashtag_feed(hashtag,cursor=next_cursor)\n",
    "    next_cursor = fetch[\"next\"]\n",
    "    for x in fetch[\"posts\"]:\n",
    "        dict1[\"id\"].append(x[\"id\"])\n",
    "        dict1[\"body\"].append(x[\"body\"])\n",
    "    \n",
    "df_hashtag_data = pd.DataFrame.from_dict(dict1)\n",
    "df_hashtag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}